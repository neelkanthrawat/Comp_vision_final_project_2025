{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e67884fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "# hyperparameter optimization rtd\n",
    "import optuna\n",
    "import wandb\n",
    "\n",
    "# os related\n",
    "import os\n",
    "\n",
    "# file handling\n",
    "\n",
    "# segmentation model\n",
    "from lora_vit import LoraVit\n",
    "from segmentation_model import SegViT\n",
    "from segmentation_head import CustomSegHead\n",
    "\n",
    "# dataset class\n",
    "from pet_dataset_class import PreprocessedPetDataset\n",
    "\n",
    "# dataloaders\n",
    "from create_dataloaders import get_pet_dataloaders\n",
    "\n",
    "# trainer\n",
    "from trainer import trainer\n",
    "\n",
    "# loss and metrics\n",
    "from loss_and_metrics_seg import * # idk what to import here tbh. Need to look into it\n",
    "\n",
    "# data plotting\n",
    "from data_plotting import plot_random_images_and_trimaps_2\n",
    "\n",
    "# modules for loading the vit model\n",
    "from transformers import ViTModel, ViTImageProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "## load the pre-trained ViT-model (86 Mil)\n",
    "model_name = 'google/vit-base-patch16-224'\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "VIT_PRETRAINED = ViTModel.from_pretrained(model_name)\n",
    "\n",
    "# instantiating the lora vit based backbone model\n",
    "lora_vit_base = LoraVit(vit_model=VIT_PRETRAINED,\n",
    "                        r=4,alpha = 16, lora_layers = [1,2,3,4])\n",
    "\n",
    "\n",
    "# # instantiate the custom segmentation head\n",
    "# check_seg_head_model = CustomSegHead(hidden_dim=768, num_classes=3, patch_size=16, image_size=224) #  do not need to do that, the SegViT model will do it automatically\n",
    "\n",
    "# instantiate the segmentation model\n",
    "vit_seg_model = SegViT(vit_model=lora_vit_base,image_size=224, patch_size=16\n",
    "                    , dim= 768,\n",
    "                    n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fe929d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001F59F1FB4C0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_seg_model.backbone_parameters # get backbone parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a1ea5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001F59F1FB5A0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_seg_model.head_parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using only 80 datapoints out of 7390 total files.\n",
      "train_size: 64, val_size: 8 and test_size: 8\n"
     ]
    }
   ],
   "source": [
    "# get path of image and mask files\n",
    "try:\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # __file__ is not defined (e.g. in Jupyter notebook or interactive sessions apparently), fallback to cwd\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Suppose your dataset is in a folder named 'data' inside the project root:\n",
    "data_dir = os.path.join(base_dir, 'data_oxford_iiit')\n",
    "\n",
    "# # Then you can define image and trimap paths relative to that\n",
    "image_folder = os.path.join(data_dir, 'resized_images')\n",
    "trimap_folder = os.path.join(data_dir, 'resized_masks')\n",
    "\n",
    "# create dataloaders\n",
    "train_dl, val_dl, test_dl = get_pet_dataloaders(\n",
    "    image_folder=image_folder,\n",
    "    mask_folder=trimap_folder,\n",
    "    DatasetClass=PreprocessedPetDataset,\n",
    "    all_data=False,\n",
    "    num_datapoints=80, # right now I am just testing whether the things would work or not. I will intentionally overtrain it.\n",
    "    batch_size=24\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input parameters for the trainer\n",
    "trainer_input_params = {\n",
    "    \"model\": vit_seg_model , \n",
    "    \"optimizer\": torch.optim.Adam([\n",
    "    {\"params\": vit_seg_model.backbone_parameters, \"lr\": 1e-5},\n",
    "    {\"params\": vit_seg_model.head_parameters, \"lr\": 1e-4},\n",
    "]),\n",
    "    \"lr\": 1e-4,\n",
    "    \"criterion\": log_cosh_dice_loss,  # or log_cosh_dice_loss, whichever you want to use\n",
    "    \"num_epoch\": 10,\n",
    "    \"dataloaders\": {\n",
    "        \"train\": train_dl,  # replace with your actual DataLoader\n",
    "        \"val\": val_dl       # replace with your actual DataLoader\n",
    "    },\n",
    "    \"use_trap_scheduler\": False,             # or your scheduler instance if you use one\n",
    "    \"device\": \"cpu\",#\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    #\"model_kwargs\": {},            # add any extra forward() kwargs if needed\n",
    "    \"criterion_kwargs\": {\n",
    "        \"num_classes\": 3,\n",
    "        \"epsilon\": 1e-6,\n",
    "        # \"return_metrics\": False    # usually False for training, True for validation if you want metrics ## WE DO NOT NEED THIS HERE\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92942690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [02:59<26:54, 179.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 0.2038 | Val Loss: 0.1671 | Dice score: 0.40576425194740295 |IOU score: 0.2783524 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [05:17<20:38, 154.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] - Train Loss: 0.1452 | Val Loss: 0.1326 | Dice score: 0.47354504466056824 |IOU score: 0.3533309 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [07:12<15:57, 136.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] - Train Loss: 0.1140 | Val Loss: 0.1115 | Dice score: 0.5189403891563416 |IOU score: 0.4039131 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [09:04<12:41, 126.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] - Train Loss: 0.0941 | Val Loss: 0.0958 | Dice score: 0.5551862120628357 |IOU score: 0.4378821 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [10:56<10:08, 121.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] - Train Loss: 0.0791 | Val Loss: 0.0860 | Dice score: 0.5792495012283325 |IOU score: 0.4553901 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [12:47<07:51, 117.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Train Loss: 0.0714 | Val Loss: 0.0810 | Dice score: 0.5920671224594116 |IOU score: 0.4649752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [14:49<05:57, 119.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] - Train Loss: 0.0642 | Val Loss: 0.0732 | Dice score: 0.6127362847328186 |IOU score: 0.4891889 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [16:56<04:03, 121.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Train Loss: 0.0577 | Val Loss: 0.0685 | Dice score: 0.6257516741752625 |IOU score: 0.5063803 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [19:11<02:05, 125.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Train Loss: 0.0538 | Val Loss: 0.0665 | Dice score: 0.6313516497612 |IOU score: 0.5125546 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [21:16<00:00, 127.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Train Loss: 0.0500 | Val Loss: 0.0660 | Dice score: 0.6327686905860901 |IOU score: 0.5116880 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instantiate the trainer\n",
    "trainer_seg_model = trainer(**trainer_input_params) \n",
    "trainer_seg_model.train() # need to look into this thing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
